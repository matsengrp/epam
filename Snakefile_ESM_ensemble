import epam.models
import subprocess

# Read parameters from the config file
dataset = config["dataset"]
number_of_batches = config["number_of_batches"]
pcp_per_batch = config["pcp_per_batch"]
pcp_input = config["pcp_input"]

model_name_to_spec = {
    model_name: [model_class, str({**model_params, "model_name": model_name})]
    for model_name, model_class, model_params in epam.models.FULLY_SPECIFIED_MODELS 
}

batch_number = range(1, number_of_batches+1)
esm_model_numbers = range(1, 6)

ensemble_models = ("ESM1v_mask", "S5FESM_mask", "ThriftyESM_mask")
ensemble_model_name_to_spec = {
    key: model_name_to_spec[key] for key in ensemble_models
}

individual_esm_models = ("ESM1v_mask", "S5FESM_mask", "ThriftyESM_mask")
individual_esm_model_name_to_spec = {
    key: model_name_to_spec[key] for key in individual_esm_models
}

model_combos = ["ensemble_set/ESM1v_mask", "esm1/ESM1v_mask", "esm2/ESM1v_mask", "esm3/ESM1v_mask", "esm4/ESM1v_mask", "esm5/ESM1v_mask", "ensemble_set/S5FESM_mask", "esm1/S5FESM_mask", "esm2/S5FESM_mask", "esm3/S5FESM_mask", "esm4/S5FESM_mask", "esm5/S5FESM_mask", "ensemble_set/ThriftyESM_mask", "esm1/ThriftyESM_mask", "esm2/ThriftyESM_mask", "esm3/ThriftyESM_mask", "esm4/ThriftyESM_mask", "esm5/ThriftyESM_mask"]

def get_model_class(model_name, set_model_name_to_spec):
    return set_model_name_to_spec.get(model_name, (None, None))[0]

def get_model_params(model_name, set_model_name_to_spec):
    return set_model_name_to_spec.get(model_name, (None, None))[1]


rule all:
    input:
        expand("output/{pcp_input}/ensemble_combined_performance.csv", pcp_input=config["pcp_input"]),
        expand("output/{pcp_input}/ensemble_combined_timing.csv", pcp_input=config["pcp_input"]),


# rule split_pcp_batches:
#     input:
#         "pcp_inputs/{pcp_input}.csv"
#     output:
#         out_csvs=dynamic("pcp_batched_inputs/{pcp_input}_{part}.csv")  
#     params:
#         output_dir="pcp_batched_inputs/",
#         batch_size=pcp_per_batch
#     shell:
#         """
#         python scripts/split_pcp_files.py {input} {params.output_dir} {params.batch_size}
#         """


rule precompute_esm:
    input:
        in_csv="pcp_batched_inputs/{pcp_input}_{part}.csv", 
    output:
        out_hdf5="pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_logits_{part}.hdf5", 
    params:
        part=lambda wildcards: wildcards.part,  # Define a dynamic wildcard for {part}
        esm_model_number=lambda wildcards: wildcards.esm_model_number
    shell: 
        """
        epam esm_bulk_precompute {input.in_csv} {output.out_hdf5} "masked-marginals" {params.esm_model_number}
        """


rule process_esm:
    input:
        in_hdf5="pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_logits_{part}.hdf5",
    output:
        rpob_out_hdf5="pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_probs_{part}.hdf5",
        ratio_out_hdf5="pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_ratios_{part}.hdf5",
    params:
        part=lambda wildcards: wildcards.part,
        esm_model_number=lambda wildcards: wildcards.esm_model_number
    wildcard_constraints:
        esm_model_number="\d+"  # This ensures esm_model_number only matches digits
    shell:
        """
        epam process_esm_output {input.in_hdf5} {output.ratio_out_hdf5} "masked-marginals"
        """


rule ensemble_esm_probs:
    input:
        expand("pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_probs_{part}.hdf5", 
               pcp_input=pcp_input, 
               esm_model_number=esm_model_numbers,
               part="{part}")
    output:
        "pcp_batched_inputs/{pcp_input}_esm_ensemble_mask_probs_{part}.hdf5",
    run:
        input_files = ",".join(input)
        output_file = output[0]
        
        subprocess.run(
            f"epam ensemble_esm_models {input_files} {output_file}", shell=True, check=True
        )


rule ensemble_esm_selection_factors:
    input:
        expand("pcp_batched_inputs/{pcp_input}_esm{esm_model_number}_mask_ratios_{part}.hdf5", 
               pcp_input=pcp_input, 
               esm_model_number=esm_model_numbers,
               part="{part}")
    output:
        "pcp_batched_inputs/{pcp_input}_esm_ensemble_mask_ratios_{part}.hdf5",
    run:
        input_files = ",".join(input)
        output_file = output[0]
        
        subprocess.run(
            f"epam ensemble_esm_models {input_files} {output_file}", shell=True, check=True
        )


rule run_esm_ensemble_models:
    input:
        in_csv="pcp_batched_inputs/{pcp_input}_{part}.csv",
        hdf5_path=lambda wildcards: (
            f"pcp_batched_inputs/{wildcards.pcp_input}_esm_ensemble_mask_probs_{wildcards.part}.hdf5"
            if wildcards.model_name == "ESM1v_mask"
            else f"pcp_batched_inputs/{wildcards.pcp_input}_esm_ensemble_mask_ratios_{wildcards.part}.hdf5"
        ),
    output:
        aaprob="output/{pcp_input}/ensemble_set/{model_name}/batch{part}/aaprob.hdf5",
    params:
        part=lambda wildcards: wildcards.part,
        model_class=lambda wildcards: get_model_class(wildcards.model_name, ensemble_model_name_to_spec),
        model_params=lambda wildcards: get_model_params(wildcards.model_name, ensemble_model_name_to_spec),
    benchmark:
        "output/{pcp_input}/ensemble_set/{model_name}/batch{part}/timing.tsv"
    wildcard_constraints:
        model_name="|".join(ensemble_models),
    shell:
        """
        mkdir -p output/{wildcards.pcp_input}/ensemble_set/{wildcards.model_name}/batch{params.part}
        epam aaprob {params.model_class} "{params.model_params}" {input.in_csv} {output.aaprob} {input.hdf5_path}
        """


rule run_esm_individual_models:
    input:
        in_csv="pcp_batched_inputs/{pcp_input}_{part}.csv",
        hdf5_path=lambda wildcards: (
            f"pcp_batched_inputs/{wildcards.pcp_input}_esm{wildcards.esm_model_number}_mask_probs_{wildcards.part}.hdf5"
            if wildcards.model_name == "ESM1v_mask"
            else f"pcp_batched_inputs/{wildcards.pcp_input}_esm{wildcards.esm_model_number}_mask_ratios_{wildcards.part}.hdf5"
        ),
    output:
        aaprob="output/{pcp_input}/esm{esm_model_number}/{model_name}/batch{part}/aaprob.hdf5",
    params:
        part=lambda wildcards: wildcards.part,
        model_class=lambda wildcards: get_model_class(wildcards.model_name, individual_esm_model_name_to_spec),
        model_params=lambda wildcards: get_model_params(wildcards.model_name, individual_esm_model_name_to_spec),
        esm_model_number=lambda wildcards: wildcards.esm_model_number
    benchmark:
        "output/{pcp_input}/esm{esm_model_number}/{model_name}/batch{part}/timing.tsv"
    wildcard_constraints:
        model_name="|".join(individual_esm_models),
    shell:
        """
        mkdir -p output/{wildcards.pcp_input}/esm{params.esm_model_number}/{wildcards.model_name}/batch{params.part}
        epam aaprob {params.model_class} "{params.model_params}" {input.in_csv} {output.aaprob} {input.hdf5_path}
        """


rule combine_aaprob_files:
    input:
        expand(
            "output/{{pcp_input}}/{{set_model}}/batch{part}/aaprob.hdf5",
            part=batch_number,
        ),
    output:
        "output/{pcp_input}/{set_model}/combined_aaprob.hdf5",
    run:
        input_files = ",".join(input)
        output_file = output[0]
        
        subprocess.run(
            f"epam concatenate_hdf5s {input_files} {output_file}", shell=True, check=True
        )


rule evaluate_performance:
    input:
        "output/{pcp_input}/{set_model}/combined_aaprob.hdf5", 
    output:
        "output/{pcp_input}/{set_model}/performance.csv",
    shell:
        """
        epam evaluate {input} {output}
        """


rule combine_performance_files:
    input:
        expand(
            "output/{pcp_input}/{set_model}/performance.csv",
            pcp_input=pcp_input,
            set_model=model_combos,
        ),
    output:
        "output/{pcp_input}/ensemble_combined_performance.csv",
        "output/{pcp_input}/ensemble_combined_timing.csv",
    run:
        import pandas as pd
        import os
        
        performance_dfs = []
        
        for input_file in input:
            df = pd.read_csv(input_file)
            
            if "esm1/" in input_file:
                ensemble_member = "1"
            elif "esm2/" in input_file:
                ensemble_member = "2"
            elif "esm3/" in input_file:
                ensemble_member = "3"
            elif "esm4/" in input_file:
                ensemble_member = "4"
            elif "esm5/" in input_file:
                ensemble_member = "5"
            elif "ensemble_set/" in input_file:
                ensemble_member = "Ensemble"
            else:
                ensemble_member = "Unknown"
                
            df["ensemble_member"] = ensemble_member
            
            path_parts = os.path.dirname(input_file).split('/')
            model_path = '/'.join(path_parts[-2:])  # Get the last two parts of the path
            df["model_path"] = model_path
            
            performance_dfs.append(df)
        
        combined_performance_df = pd.concat(performance_dfs, ignore_index=True)
        combined_performance_df.to_csv(output[0], index=False)
        
        input_timing_files = [
            f"output/{pcp_input}/{set_model}/batch{part}/timing.tsv"
            for set_model in model_combos
            for part in batch_number
        ]
        
        subprocess.run(
            f"epam concatenate_csvs {','.join(input_timing_files)} {output[1]} --is_tsv --record_path",
            shell=True,
            check=True,
        )