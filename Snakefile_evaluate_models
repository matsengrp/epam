import epam.models
import subprocess

# Read parameters from the config file
dataset = config["dataset"]
number_of_batches = config["number_of_batches"]
pcp_per_batch = config["pcp_per_batch"]
pcp_input = config["pcp_input"]

model_name_to_spec = {
    model_name: [model_class, str({**model_params, "model_name": model_name})]
    for model_name, model_class, model_params in epam.models.FULLY_SPECIFIED_MODELS 
}

batch_number = range(1, number_of_batches+1)

rule all:
    input:
        expand("output/{pcp_input}/combined_performance.csv", pcp_input=config["pcp_input"]),
        expand("output/{pcp_input}/combined_timing.csv", pcp_input=config["pcp_input"]),


rule evaluate_performance:
    input:
        "output/{pcp_input}/{model_name}/combined_aaprob.hdf5", 
    output:
        "output/{pcp_input}/{model_name}/performance.csv",
    shell:
        """
        epam evaluate {input} {output}
        """


rule combine_performance_files:
    input:
        expand(
            "output/{pcp_input}/{model_name}/performance.csv",
            pcp_input=pcp_input,
            model_name=model_name_to_spec.keys(),
        ),
    output:
        "output/{pcp_input}/combined_performance.csv",
        "output/{pcp_input}/combined_timing.csv",
    run:
        input_files = ",".join(input)
        input_timing_files = ",".join(
            f"output/{pcp_input}/{model_name}/batch{part}/timing.tsv"
            for model_name in model_name_to_spec.keys()
            for part in batch_number
        )
        output_file = output[0]
        output_timing_file = output[1]
        subprocess.run(
            f"epam concatenate_csvs {input_files} {output_file}", shell=True, check=True
        )
        subprocess.run(
            f"epam concatenate_csvs {input_timing_files} {output_timing_file} --is_tsv --record_path",
            shell=True,
            check=True,
        )
