{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from epam.dnsm import TransformerBinarySelectionModel, DNSMBurrito\n",
    "from epam.sequences import translate_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2000 PCPs.\n"
     ]
    }
   ],
   "source": [
    "pcp_df = pd.read_csv(\"~/data/wyatt-10x-1p5m_pcp_2023-10-07.csv\")\n",
    "\n",
    "# filter out rows of pcp_df where the parent and child sequences are identical\n",
    "pcp_df = pcp_df[pcp_df[\"parent\"] != pcp_df[\"child\"]]\n",
    "\n",
    "# NOTE downsampling here\n",
    "pcp_df = pcp_df.sample(20000, random_state=42)\n",
    "\n",
    "print(f\"We have {len(pcp_df)} PCPs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal Performance Shaders\n",
      "preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting mutabilities and substitutions...\n",
      "consolidating this into substitution probabilities...\n",
      "predicting mutabilities and substitutions...\n",
      "consolidating this into substitution probabilities...\n",
      "Epoch [0/3], Training Loss: 0.14439820498228073, Validation Loss: 0.14166443049907684\n",
      "training model...\n",
      "Epoch [1/3], Training Loss: 0.14281409978866577, Validation Loss: 0.1405491679906845\n",
      "Epoch [2/3], Training Loss: 0.13496620953083038, Validation Loss: 0.13836506009101868\n",
      "Epoch [3/3], Training Loss: 0.13516797125339508, Validation Loss: 0.13909541070461273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding optimal branch lengths:  29%|██▉       | 471/1600 [00:55<02:13,  8.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matsen/re/epam/notebooks/dnsm.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsen/re/epam/notebooks/dnsm.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m burrito \u001b[39m=\u001b[39m DNSMBurrito(pcp_df, shmple_weights_directory, dnsm, batch_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, checkpoint_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./_checkpoints\u001b[39m\u001b[39m\"\u001b[39m, log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./_logs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsen/re/epam/notebooks/dnsm.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m burrito\u001b[39m.\u001b[39mtrain(\u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matsen/re/epam/notebooks/dnsm.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m burrito\u001b[39m.\u001b[39;49moptimize_branch_lengths()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsen/re/epam/notebooks/dnsm.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m burrito\u001b[39m.\u001b[39mtrain(\u001b[39m15\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsen/re/epam/notebooks/dnsm.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m burrito\u001b[39m.\u001b[39moptimize_branch_lengths()\n",
      "File \u001b[0;32m~/re/epam/epam/dnsm.py:376\u001b[0m, in \u001b[0;36mDNSMBurrito.optimize_branch_lengths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize_branch_lengths\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    375\u001b[0m     \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_set, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_set]:\n\u001b[0;32m--> 376\u001b[0m         dataset\u001b[39m.\u001b[39mbranch_lengths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrapped_dnsm\u001b[39m.\u001b[39;49mfind_optimal_branch_lengths(\n\u001b[1;32m    377\u001b[0m             dataset\u001b[39m.\u001b[39;49mnt_parents, dataset\u001b[39m.\u001b[39;49mnt_children, dataset\u001b[39m.\u001b[39;49mbranch_lengths\n\u001b[1;32m    378\u001b[0m         )\n",
      "File \u001b[0;32m~/re/epam/epam/models.py:391\u001b[0m, in \u001b[0;36mOptimizableSHMple.find_optimal_branch_lengths\u001b[0;34m(self, nt_parents, nt_children, base_branch_lengths)\u001b[0m\n\u001b[1;32m    383\u001b[0m optimal_lengths \u001b[39m=\u001b[39m []\n\u001b[1;32m    385\u001b[0m \u001b[39mfor\u001b[39;00m parent, child, base_length \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m    386\u001b[0m     \u001b[39mzip\u001b[39m(nt_parents, nt_children, base_branch_lengths),\n\u001b[1;32m    387\u001b[0m     total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(nt_parents),\n\u001b[1;32m    388\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinding optimal branch lengths\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     optimal_lengths\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_optimal_branch_length(parent, child, base_length)\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(optimal_lengths)\n",
      "File \u001b[0;32m~/re/epam/epam/models.py:343\u001b[0m, in \u001b[0;36mOptimizableSHMple._find_optimal_branch_length\u001b[0;34m(self, parent, child, base_branch_length)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_find_optimal_branch_length\u001b[39m(\u001b[39mself\u001b[39m, parent, child, base_branch_length):\n\u001b[1;32m    330\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m    Find the optimal branch length for a parent-child pair in terms of\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    nucleotide likelihood.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    Tensor: The optimal branch length.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     rates, sub_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_rates_and_normed_sub_probs(\n\u001b[1;32m    344\u001b[0m         parent, base_branch_length\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    347\u001b[0m     log_pcp_probability \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_log_pcp_probability(\n\u001b[1;32m    348\u001b[0m         parent, child, rates, sub_probs\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    351\u001b[0m     log_branch_scaling \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.0\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/re/epam/epam/models.py:226\u001b[0m, in \u001b[0;36mSHMple.predict_rates_and_normed_sub_probs\u001b[0;34m(self, parent, branch_length)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_rates_and_normed_sub_probs\u001b[39m(\n\u001b[1;32m    208\u001b[0m     \u001b[39mself\u001b[39m, parent: \u001b[39mstr\u001b[39m, branch_length: \u001b[39mfloat\u001b[39m\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    210\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m    A wrapper for the predict_mutabilities_and_substitutions method of the\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    SHMple model that normalizes the substitution probabilities, as well as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m        substitution probabilities as Torch tensors.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     [rates], [subs] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_mutabilities_and_substitutions(\n\u001b[1;32m    227\u001b[0m         [parent], [branch_length]\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m     parent_idxs \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39mnt_idx_tensor_of_str(parent)\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(rates\u001b[39m.\u001b[39msqueeze()), molevol\u001b[39m.\u001b[39mnormalize_sub_probs(\n\u001b[1;32m    231\u001b[0m         parent_idxs, torch\u001b[39m.\u001b[39mtensor(subs)\n\u001b[1;32m    232\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/shmple/models/attention_model.py:231\u001b[0m, in \u001b[0;36mAttentionModel.predict_mutabilities_and_substitutions\u001b[0;34m(self, germline_seqs, branch_lengths, mutation_sites, random_seed)\u001b[0m\n\u001b[1;32m    228\u001b[0m encoded_lengths \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(lengths)\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mComputing mutabilities and substitution rates...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 231\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mseq_inputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: encoded_orig,\n\u001b[1;32m    234\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mbranch_inputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: encoded_lengths,\n\u001b[1;32m    235\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mseq_mask_inputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: np\u001b[39m.\u001b[39;49mstack(masks),\n\u001b[1;32m    236\u001b[0m     },\n\u001b[1;32m    237\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mgetEffectiveLevel() \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m logging\u001b[39m.\u001b[39;49mINFO),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    238\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    241\u001b[0m lambda_tensor \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mmutations\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    242\u001b[0m sub_tensor \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39msubstitutions\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/keras/src/engine/training.py:2550\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2548\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[1;32m   2549\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2550\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2551\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2552\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1331\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[1;32m   1332\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[1;32m   1333\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[1;32m    505\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    706\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    707\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 710\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[1;32m    712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/epam/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:716\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_iterator\u001b[39m(\u001b[39mself\u001b[39m, dataset):\n\u001b[1;32m    715\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m   dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49m_apply_debug_options()\n\u001b[1;32m    718\u001b[0m   \u001b[39m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[39;00m\n\u001b[1;32m    719\u001b[0m   \u001b[39m# is being used. For example, `tf.data.Dataset.from_generator` registers\u001b[39;00m\n\u001b[1;32m    720\u001b[0m   \u001b[39m# a few py_funcs that are needed in `self._next_internal`.  If the dataset\u001b[39;00m\n\u001b[1;32m    721\u001b[0m   \u001b[39m# is deleted, this iterator crashes on `self.__next__(...)` call.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset \u001b[39m=\u001b[39m dataset\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shmple_weights_directory = \"/Users/matsen/re/epam/data/shmple_weights/my_shmoof\"\n",
    "nhead = 4\n",
    "dim_feedforward = 2048\n",
    "layer_count = 3\n",
    "\n",
    "dnsm = TransformerBinarySelectionModel(\n",
    "    nhead=nhead, dim_feedforward=dim_feedforward, layer_count=layer_count\n",
    ")\n",
    "\n",
    "burrito = DNSMBurrito(pcp_df, shmple_weights_directory, dnsm, batch_size=1024, learning_rate=0.001, checkpoint_dir=\"./_checkpoints\", log_dir=\"./_logs\")\n",
    "\n",
    "burrito.train(3)\n",
    "burrito.optimize_branch_lengths()\n",
    "burrito.train(15)\n",
    "burrito.optimize_branch_lengths()\n",
    "burrito.train(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16746567, 0.18125452, 0.17475654, 0.14934239, 0.19283801,\n",
       "       0.17483354, 0.22327097, 0.15719528, 0.2670195 , 0.15506317,\n",
       "       0.15051098, 0.3086634 , 0.30574813, 0.16796537, 0.15364574,\n",
       "       0.27505472, 0.2421864 , 0.19693483, 0.30720553, 0.20181261,\n",
       "       0.2733704 , 0.15934032, 0.32970226, 0.30831188, 0.28278762,\n",
       "       0.16281629, 0.25050843, 0.3119859 , 0.16555636, 0.2933701 ,\n",
       "       0.25556317, 0.21109025, 0.15875149, 0.15081373, 0.2629757 ,\n",
       "       0.15331246, 0.22006264, 0.17811066, 0.21454369, 0.3095778 ,\n",
       "       0.23798394, 0.1833422 , 0.23784602, 0.17310007, 0.15132064,\n",
       "       0.1633514 , 0.15469873, 0.31436643, 0.17545184, 0.15432854,\n",
       "       0.30028984, 0.3328726 , 0.34694675, 0.34256014, 0.34860313,\n",
       "       0.23313344, 0.3446737 , 0.3190169 , 0.35119778, 0.32210308,\n",
       "       0.34833214, 0.30879936, 0.23360679, 0.28930157, 0.3455299 ,\n",
       "       0.24755357, 0.30245617, 0.3314089 , 0.32135543, 0.33970687,\n",
       "       0.3460881 , 0.20939623, 0.3135103 , 0.34284648, 0.33584425,\n",
       "       0.3130739 , 0.336011  , 0.33908415, 0.33742192, 0.29846317,\n",
       "       0.16207898, 0.28402993, 0.3423188 , 0.34661597, 0.34805113,\n",
       "       0.17522612, 0.35532758, 0.35745242, 0.23623493, 0.33187583,\n",
       "       0.3499309 , 0.35142112, 0.31455705, 0.30161962, 0.3005234 ,\n",
       "       0.21187077, 0.3486743 , 0.30464485, 0.28173795, 0.29233566,\n",
       "       0.35258058, 0.34899598, 0.3418285 , 0.32714877, 0.29871058,\n",
       "       0.23297775, 0.26056543, 0.24981105, 0.16821599, 0.2358194 ,\n",
       "       0.22353631, 0.23807512, 0.15770745, 0.17852601, 0.24331413,\n",
       "       0.19380358, 0.3188701 , 0.15545212, 0.2669545 , 0.30769703,\n",
       "       0.26620817, 0.31014338, 0.3033684 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[aa_str] = translate_sequences([pcp_df.reset_index(drop=True).loc[0, \"parent\"]])\n",
    "burrito.dnsm.selection_factors_of_aa_str(aa_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal Performance Shaders\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16746567, 0.18125452, 0.17475654, 0.14934239, 0.19283801,\n",
       "       0.17483354, 0.22327097, 0.15719528, 0.2670195 , 0.15506317,\n",
       "       0.15051098, 0.3086634 , 0.30574813, 0.16796537, 0.15364574,\n",
       "       0.27505472, 0.2421864 , 0.19693483, 0.30720553, 0.20181261,\n",
       "       0.2733704 , 0.15934032, 0.32970226, 0.30831188, 0.28278762,\n",
       "       0.16281629, 0.25050843, 0.3119859 , 0.16555636, 0.2933701 ,\n",
       "       0.25556317, 0.21109025, 0.15875149, 0.15081373, 0.2629757 ,\n",
       "       0.15331246, 0.22006264, 0.17811066, 0.21454369, 0.3095778 ,\n",
       "       0.23798394, 0.1833422 , 0.23784602, 0.17310007, 0.15132064,\n",
       "       0.1633514 , 0.15469873, 0.31436643, 0.17545184, 0.15432854,\n",
       "       0.30028984, 0.3328726 , 0.34694675, 0.34256014, 0.34860313,\n",
       "       0.23313344, 0.3446737 , 0.3190169 , 0.35119778, 0.32210308,\n",
       "       0.34833214, 0.30879936, 0.23360679, 0.28930157, 0.3455299 ,\n",
       "       0.24755357, 0.30245617, 0.3314089 , 0.32135543, 0.33970687,\n",
       "       0.3460881 , 0.20939623, 0.3135103 , 0.34284648, 0.33584425,\n",
       "       0.3130739 , 0.336011  , 0.33908415, 0.33742192, 0.29846317,\n",
       "       0.16207898, 0.28402993, 0.3423188 , 0.34661597, 0.34805113,\n",
       "       0.17522612, 0.35532758, 0.35745242, 0.23623493, 0.33187583,\n",
       "       0.3499309 , 0.35142112, 0.31455705, 0.30161962, 0.3005234 ,\n",
       "       0.21187077, 0.3486743 , 0.30464485, 0.28173795, 0.29233566,\n",
       "       0.35258058, 0.34899598, 0.3418285 , 0.32714877, 0.29871058,\n",
       "       0.23297775, 0.26056543, 0.24981105, 0.16821599, 0.2358194 ,\n",
       "       0.22353631, 0.23807512, 0.15770745, 0.17852601, 0.24331413,\n",
       "       0.19380358, 0.3188701 , 0.15545212, 0.2669545 , 0.30769703,\n",
       "       0.26620817, 0.31014338, 0.3033684 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhead = 4\n",
    "dim_feedforward = 2048\n",
    "layer_count = 3\n",
    "\n",
    "model = TransformerBinarySelectionModel(\n",
    "    nhead=nhead, dim_feedforward=dim_feedforward, layer_count=layer_count\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"/Users/matsen/re/epam/trained_dnsms/dnsm-2023-11-01-09-32.pth\")[\"model_state_dict\"])\n",
    "model.eval()\n",
    "model.selection_factors_of_aa_str(aa_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
